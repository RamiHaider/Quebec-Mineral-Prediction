{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074da0f2-6db8-491b-b0fd-e8e78fc6637c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with 434850 samples\n",
      "Features: ['CODE_LITH_encoded', 'STRAT_encoded', 'dist_fault', 'dist_cont']\n",
      "Labels: ['AU_target', 'AG_target', 'CU_target', 'CO_target', 'NI_target']\n",
      "AU_target - Positive samples: 11700, Weight: 12.00\n",
      "AG_target - Positive samples: 15123, Weight: 12.00\n",
      "CU_target - Positive samples: 10662, Weight: 7.00\n",
      "CO_target - Positive samples: 8549, Weight: 7.00\n",
      "NI_target - Positive samples: 17449, Weight: 5.00\n",
      "\n",
      "Starting training with:\n",
      "Device: cpu\n",
      "Train samples: 347880\n",
      "Validation samples: 86970\n",
      "Batch size: 64\n",
      "Learning rate: 0.0005\n",
      "\n",
      "Epoch [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████| 5436/5436 [2:51:08<00:00,  1.89s/it, loss=0.4294]\n",
      "Validating: 100%|███████████████████████████████████████████████| 1359/1359 [19:17<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.4294\n",
      "Validation Loss: 0.3686\n",
      "\n",
      "Prediction Summary:\n",
      "AU:\n",
      "  Predicted positive: 6299.0\n",
      "  Actually positive: 2324.0\n",
      "  AUC Score: 0.8118\n",
      "AG:\n",
      "  Predicted positive: 6397.0\n",
      "  Actually positive: 3041.0\n",
      "  AUC Score: 0.7052\n",
      "CU:\n",
      "  Predicted positive: 2889.0\n",
      "  Actually positive: 2163.0\n",
      "  AUC Score: 0.6871\n",
      "CO:\n",
      "  Predicted positive: 3212.0\n",
      "  Actually positive: 1663.0\n",
      "  AUC Score: 0.7736\n",
      "NI:\n",
      "  Predicted positive: 4841.0\n",
      "  Actually positive: 3426.0\n",
      "  AUC Score: 0.8039\n",
      "\n",
      "Saved model to: /Users/ramiab/Desktop/Mineral-Predictions-Local/Training/models/cnn_model_20250125_epoch1.pt\n",
      "\n",
      "Epoch [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                     | 8/5436 [00:22<4:10:51,  2.77s/it, loss=0.3118]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "DATA_DIR   = \"/Users/ramiab/Desktop/Mineral-Predictions-Local\"\n",
    "CSV_PATH   = os.path.join(DATA_DIR, \"Training\", \"data\", \"preprocessed\", \"rock_features.csv\")\n",
    "IMG_DIR    = os.path.join(DATA_DIR, \"Images\", \"Rock-Mag-Images\")\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "LR         = 5e-4  # Changed to optimal learning rate\n",
    "VAL_SPLIT  = 0.2\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LABEL_NAMES = ['AU','AG','CU','CO','NI']\n",
    "\n",
    "# Make sure models directory exists\n",
    "os.makedirs(os.path.join(DATA_DIR, \"Training\", \"models\"), exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Model Architecture\n",
    "# ---------------------------\n",
    "class MineralMultiModalNet(nn.Module):\n",
    "   def __init__(self, num_classes=5, num_geological_features=None):\n",
    "       super().__init__()\n",
    "       \n",
    "       # 1. CNN Branch (for magnetic images) - Optimized 3-layer architecture\n",
    "       self.cnn_branch = nn.Sequential(\n",
    "           # First CNN Block\n",
    "           nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "           nn.BatchNorm2d(32),\n",
    "           nn.ReLU(),\n",
    "           nn.MaxPool2d(2),\n",
    "           \n",
    "           # Second CNN Block\n",
    "           nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "           nn.BatchNorm2d(64),\n",
    "           nn.ReLU(),\n",
    "           nn.MaxPool2d(2),\n",
    "           \n",
    "           # Third CNN Block\n",
    "           nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "           nn.BatchNorm2d(128),\n",
    "           nn.ReLU(),\n",
    "           nn.MaxPool2d(2),\n",
    "       )\n",
    "       \n",
    "       # 2. Geological Features Branch\n",
    "       self.geo_branch = nn.Sequential(\n",
    "           nn.Linear(num_geological_features, 256),\n",
    "           nn.BatchNorm1d(256),\n",
    "           nn.ReLU(),\n",
    "           nn.Dropout(0.3),\n",
    "           nn.Linear(256, 128),\n",
    "           nn.BatchNorm1d(128),\n",
    "           nn.ReLU(),\n",
    "           nn.Dropout(0.2)\n",
    "       )\n",
    "       \n",
    "       # Calculate CNN output size (170 -> 85 -> 42 -> 21)\n",
    "       cnn_output_size = 128 * 21 * 21\n",
    "       \n",
    "       # 3. Combination Layer\n",
    "       self.combiner = nn.Sequential(\n",
    "           nn.Linear(cnn_output_size + 128, 512),\n",
    "           nn.BatchNorm1d(512),\n",
    "           nn.ReLU(),\n",
    "           nn.Dropout(0.3),\n",
    "           nn.Linear(512, 256),\n",
    "           nn.BatchNorm1d(256),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(256, num_classes)\n",
    "       )\n",
    "   \n",
    "   def forward(self, img, geo_features):\n",
    "       # Process image through CNN\n",
    "       x_img = self.cnn_branch(img)\n",
    "       x_img = x_img.view(x_img.size(0), -1)\n",
    "       \n",
    "       # Process geological features\n",
    "       x_geo = self.geo_branch(geo_features)\n",
    "       \n",
    "       # Combine both feature sets\n",
    "       combined = torch.cat([x_img, x_geo], dim=1)\n",
    "       \n",
    "       # Final prediction\n",
    "       return self.combiner(combined)\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset\n",
    "# ---------------------------\n",
    "class MineralDataset(Dataset):\n",
    "   def __init__(self, csv_file, img_dir, transform=None):\n",
    "       self.df = pd.read_csv(csv_file)\n",
    "       \n",
    "       # Get feature columns (excluding targets and ID)\n",
    "       self.feature_cols = ['CODE_LITH_encoded', 'STRAT_encoded', \n",
    "                          'dist_fault', 'dist_cont']\n",
    "       self.label_cols = [col for col in self.df.columns if col.endswith('_target')]\n",
    "       \n",
    "       self.img_dir = img_dir\n",
    "       self.transform = transform\n",
    "       \n",
    "       print(f\"Dataset initialized with {len(self.df)} samples\")\n",
    "       print(f\"Features: {self.feature_cols}\")\n",
    "       print(f\"Labels: {self.label_cols}\")\n",
    "       \n",
    "   def __len__(self):\n",
    "       return len(self.df)\n",
    "   \n",
    "   def __getitem__(self, idx):\n",
    "       row = self.df.iloc[idx]\n",
    "       \n",
    "       # Get image\n",
    "       img_id = int(row['UNIQUE_ID'])\n",
    "       img_path = os.path.join(self.img_dir, f\"{img_id}.jpg\")\n",
    "       img = Image.open(img_path).convert('RGB')\n",
    "       if self.transform:\n",
    "           img = self.transform(img)\n",
    "           \n",
    "       # Get geological features\n",
    "       geo_features = torch.tensor(row[self.feature_cols].values, \n",
    "                                 dtype=torch.float32)\n",
    "       \n",
    "       # Get targets\n",
    "       targets = torch.tensor(row[self.label_cols].values, \n",
    "                            dtype=torch.float32)\n",
    "       \n",
    "       return img, geo_features, targets\n",
    "\n",
    "# ---------------------------\n",
    "# Training Functions\n",
    "# ---------------------------\n",
    "def compute_class_weights(df, target_cols):\n",
    "   weights = []\n",
    "   for col in target_cols:\n",
    "       base_weight = (1 - df[col].mean()) / df[col].mean()\n",
    "       \n",
    "       # Optimized weights based on hyperparameter tuning\n",
    "       if col == 'AU_target':\n",
    "           adjusted_weight = 12.0  # Sweet spot from testing\n",
    "       elif col == 'AG_target':\n",
    "           adjusted_weight = 12.0  # Sweet spot from testing\n",
    "       elif col == 'CU_target':\n",
    "           adjusted_weight = 7.0   # Sweet spot from testing\n",
    "       elif col == 'CO_target':\n",
    "           adjusted_weight = 7.0   # Sweet spot from testing\n",
    "       elif col == 'NI_target':\n",
    "           adjusted_weight = 5.0   # Sweet spot from testing\n",
    "           \n",
    "       weights.append(adjusted_weight)\n",
    "       print(f\"{col} - Positive samples: {df[col].sum()}, Weight: {adjusted_weight:.2f}\")\n",
    "   return torch.tensor(weights)\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer):\n",
    "   model.train()\n",
    "   running_loss = 0.0\n",
    "   pbar = tqdm(train_loader, desc=f\"Training\", ncols=100)\n",
    "   \n",
    "   for images, geo_features, targets in pbar:\n",
    "       images = images.to(DEVICE)\n",
    "       geo_features = geo_features.to(DEVICE)\n",
    "       targets = targets.to(DEVICE)\n",
    "       \n",
    "       optimizer.zero_grad()\n",
    "       outputs = model(images, geo_features)\n",
    "       loss = criterion(outputs, targets)\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "       \n",
    "       running_loss += loss.item()\n",
    "       pbar.set_postfix({'loss': f\"{running_loss / (pbar.n + 1):.4f}\"})\n",
    "   \n",
    "   return running_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "   model.eval()\n",
    "   val_loss = 0\n",
    "   all_preds = []\n",
    "   all_targets = []\n",
    "   pred_counts = {label: 0 for label in LABEL_NAMES}\n",
    "   true_counts = {label: 0 for label in LABEL_NAMES}\n",
    "   \n",
    "   with torch.no_grad():\n",
    "       for images, geo_features, targets in tqdm(val_loader, desc=\"Validating\", ncols=100):\n",
    "           images = images.to(DEVICE)\n",
    "           geo_features = geo_features.to(DEVICE)\n",
    "           targets = targets.to(DEVICE)\n",
    "           \n",
    "           outputs = model(images, geo_features)\n",
    "           loss = criterion(outputs, targets)\n",
    "           val_loss += loss.item()\n",
    "           \n",
    "           # Convert to probabilities and predictions\n",
    "           probs = torch.sigmoid(outputs)\n",
    "           preds = (probs >= 0.5).float()\n",
    "           \n",
    "           # Store predictions and targets\n",
    "           all_preds.append(preds.cpu())\n",
    "           all_targets.append(targets.cpu())\n",
    "           \n",
    "           # Count predictions and true values\n",
    "           for i, label in enumerate(LABEL_NAMES):\n",
    "               pred_counts[label] += preds[:, i].sum().item()\n",
    "               true_counts[label] += targets[:, i].sum().item()\n",
    "   \n",
    "   # Combine all predictions and targets\n",
    "   all_preds = torch.cat(all_preds, dim=0)\n",
    "   all_targets = torch.cat(all_targets, dim=0)\n",
    "   \n",
    "   # Calculate AUC for each mineral\n",
    "   aucs = {}\n",
    "   for i, label in enumerate(LABEL_NAMES):\n",
    "       if len(torch.unique(all_targets[:, i])) > 1:\n",
    "           aucs[label] = roc_auc_score(all_targets[:, i], all_preds[:, i])\n",
    "       else:\n",
    "           aucs[label] = float('nan')\n",
    "   \n",
    "   return {\n",
    "       'val_loss': val_loss / len(val_loader),\n",
    "       'aucs': aucs,\n",
    "       'pred_counts': pred_counts,\n",
    "       'true_counts': true_counts\n",
    "   }\n",
    "\n",
    "# ---------------------------\n",
    "# Main Training Loop\n",
    "# ---------------------------\n",
    "def main():\n",
    "   # Set up transforms\n",
    "   transform = transforms.Compose([\n",
    "       transforms.Resize((170, 170)),\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "   ])\n",
    "   \n",
    "   # Create dataset\n",
    "   dataset = MineralDataset(CSV_PATH, IMG_DIR, transform=transform)\n",
    "   \n",
    "   # Calculate number of geological features\n",
    "   num_geo_features = len(dataset.feature_cols)\n",
    "   \n",
    "   # Create train/val split\n",
    "   val_size = int(len(dataset) * VAL_SPLIT)\n",
    "   train_size = len(dataset) - val_size\n",
    "   train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "   \n",
    "   train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "   val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "   \n",
    "   # Initialize model\n",
    "   model = MineralMultiModalNet(num_classes=len(LABEL_NAMES), \n",
    "                               num_geological_features=num_geo_features).to(DEVICE)\n",
    "   \n",
    "   # Calculate class weights\n",
    "   target_cols = [col for col in dataset.df.columns if col.endswith('_target')]\n",
    "   class_weights = compute_class_weights(dataset.df, target_cols).to(DEVICE)\n",
    "   \n",
    "   # Loss and optimizer\n",
    "   criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "   optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "   \n",
    "   print(f\"\\nStarting training with:\")\n",
    "   print(f\"Device: {DEVICE}\")\n",
    "   print(f\"Train samples: {train_size}\")\n",
    "   print(f\"Validation samples: {val_size}\")\n",
    "   print(f\"Batch size: {BATCH_SIZE}\")\n",
    "   print(f\"Learning rate: {LR}\")\n",
    "   \n",
    "   # Training loop\n",
    "   for epoch in range(NUM_EPOCHS):\n",
    "       print(f\"\\nEpoch [{epoch+1}/{NUM_EPOCHS}]\")\n",
    "       \n",
    "       # Train\n",
    "       train_loss = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "       \n",
    "       # Validate\n",
    "       val_metrics = validate(model, val_loader, criterion)\n",
    "       \n",
    "       # Print epoch summary\n",
    "       print(f\"\\nTraining Loss: {train_loss:.4f}\")\n",
    "       print(f\"Validation Loss: {val_metrics['val_loss']:.4f}\")\n",
    "       print(\"\\nPrediction Summary:\")\n",
    "       for label in LABEL_NAMES:\n",
    "           print(f\"{label}:\")\n",
    "           print(f\"  Predicted positive: {val_metrics['pred_counts'][label]}\")\n",
    "           print(f\"  Actually positive: {val_metrics['true_counts'][label]}\")\n",
    "           print(f\"  AUC Score: {val_metrics['aucs'][label]:.4f}\")\n",
    "       \n",
    "       # Save model\n",
    "       timestamp = datetime.now().strftime('%Y%m%d')\n",
    "       model_path = os.path.join(DATA_DIR, \"Training\", \"models\", \n",
    "                                f\"cnn_model_{timestamp}_epoch{epoch+1}.pt\")\n",
    "       \n",
    "       torch.save({\n",
    "           'epoch': epoch + 1,\n",
    "           'model_state_dict': model.state_dict(),\n",
    "           'optimizer_state_dict': optimizer.state_dict(),\n",
    "           'train_loss': train_loss,\n",
    "           'val_metrics': val_metrics,\n",
    "           'model': model  # Save complete model\n",
    "       }, model_path)\n",
    "       \n",
    "       print(f\"\\nSaved model to: {model_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637e4f9-5234-44fa-9526-fe19fef9338e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
